{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arush\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:34: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image \n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model(\"ie_final_3epo_vgg_sahil.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def otsu_bin(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, binary_image = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    binary_image = cv2.bitwise_not(binary_image)\n",
    "\n",
    "    return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_and_predict(frame):\n",
    "    \n",
    "    img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    target_aspect_ratio = 240 / 195\n",
    "\n",
    "    original_aspect_ratio = width / height\n",
    "\n",
    "    if original_aspect_ratio > target_aspect_ratio:\n",
    "        new_height = height\n",
    "        new_width = int(height * target_aspect_ratio)\n",
    "        left = (width - new_width) // 2\n",
    "        right = left + new_width\n",
    "        top = 0\n",
    "        bottom = height\n",
    "    else:\n",
    "        new_width = width\n",
    "        new_height = int(width / target_aspect_ratio)\n",
    "        top = (height - new_height) // 2\n",
    "        bottom = top + new_height\n",
    "        left = 0\n",
    "        right = width\n",
    "\n",
    "    img = img[top:bottom, left:right]\n",
    "\n",
    "    img = image.smart_resize(img, (224, 224))\n",
    "\n",
    "    x = img / 255.0\n",
    "\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    #class_names = ['call_me', 'okay', 'paper','Rock','up']\n",
    "    class_names = ['Right', 'Left', 'Stop','Forward','Backward']\n",
    "    predicted_class_idx = np.argmax(predictions)\n",
    "    predicted_class = class_names[predicted_class_idx]\n",
    "    \n",
    "    return predicted_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(preprocess_and_predict(\"up.jpg\"))\n",
    "# print(preprocess_and_predict(\"call_me.jpg\"))\n",
    "# print(preprocess_and_predict(\"okay.jpg\"))\n",
    "# print(preprocess_and_predict(\"rock.jpg\"))\n",
    "# print(preprocess_and_predict(\"test_paper.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "Stop\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
      "Right\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "Forward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "Backward\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "Right\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import serial\n",
    "import time\n",
    "\n",
    "# Open the default camera (usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(\"http://192.168.53.124:4747/video\")\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Capture video frame by frame\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully read\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "    frame=otsu_bin(frame)\n",
    "    frame = cv2.resize(frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "# Rotate left (counter-clockwise)\n",
    "    #frame_rotated_left = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "    # Display the frame\n",
    "    window_width = 600  # Adjust this value as per your requirement\n",
    "    window_height = 600  # Adjust this value as per your requirement\n",
    "    cv2.namedWindow('Webcam', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Webcam', window_width, window_height)\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    # print(preprocess_and_predict(frame))\n",
    "\n",
    "    # Check for key press\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('p'):  # Press 'q' to quit\n",
    "        print(preprocess_and_predict(frame))\n",
    "        \n",
    "        ################################################\n",
    "        # Configure the serial port\n",
    "        ser = serial.Serial('COM3', 9600)  # Change 'COM3' to the appropriate port\n",
    "        time.sleep(2)  # Allow time for Arduino to reset\n",
    "\n",
    "        # Send data to Arduino\n",
    "        if preprocess_and_predict(frame)=='Backward':\n",
    "            ser.write(b'B\\n')\n",
    "        elif preprocess_and_predict(frame)=='Forward':\n",
    "                ser.write(b'F\\n')\n",
    "        elif preprocess_and_predict(frame)=='Right':\n",
    "            ser.write(b'R\\n')\n",
    "        elif preprocess_and_predict(frame)=='Left':\n",
    "            ser.write(b'L\\n')\n",
    "        elif preprocess_and_predict(frame)=='Stop':\n",
    "            ser.write(b'S\\n')\n",
    "            \n",
    "        # Close the serial port\n",
    "        ser.close()\n",
    "        ###################################################\n",
    "        \n",
    "    elif key== ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to your input image\n",
    "# image_path = 'input.jpg'\n",
    "\n",
    "# # Call the function to get the binary image\n",
    "# binary_img = otsu_binar(image_path)\n",
    "\n",
    "# window_width = 600  # Adjust this value as per your requirement\n",
    "# window_height = 600  # Adjust this value as per your requirement\n",
    "# cv2.namedWindow('Binary Image', cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow('Binary Image', window_width, window_height)\n",
    "\n",
    "# # Display the binary image\n",
    "# cv2.imshow('Binary Image', binary_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def image_binarization(img_path):\n",
    "#     # Load the image\n",
    "#     img = image.load_img(img_path)\n",
    "#     img = image.img_to_array(img)\n",
    "\n",
    "#     # Flatten the image\n",
    "#     image_flattened = img.reshape((-1, 1))\n",
    "\n",
    "#     # Apply K-Means clustering\n",
    "#     kmeans = KMeans(n_clusters=2)\n",
    "#     kmeans.fit(image_flattened)\n",
    "\n",
    "#     # Get the centroids\n",
    "#     centroids = kmeans.cluster_centers_\n",
    "\n",
    "#     # Binarize the image\n",
    "#     binary_image = np.where(img > centroids.mean(), 255, 0).astype(np.uint8)\n",
    "#     binary_image = binary_image.reshape(img.shape)\n",
    "\n",
    "#     return binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to your input image\n",
    "# img_path = 'input.jpg'\n",
    "\n",
    "# # Call the function to get the binary image\n",
    "# binary_img = image_binarization(img_path)\n",
    "\n",
    "# # Display the original and binary images\n",
    "# plt.subplot(1, 2, 1), plt.imshow(image.load_img(img_path), cmap='gray'), plt.title('Original Image')\n",
    "# plt.subplot(1, 2, 2), plt.imshow(binary_img, cmap='gray'), plt.title('Binary Image')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def preprocess_and_predict(img_path):\n",
    "#     img = image.load_img(img_path)\n",
    "#     img = image.img_to_array(img)\n",
    "\n",
    "#     height, width, channels = img.shape\n",
    "\n",
    "#     target_aspect_ratio = 240 / 195\n",
    "\n",
    "#     original_aspect_ratio = width / height\n",
    "\n",
    "#     if original_aspect_ratio > target_aspect_ratio:\n",
    "#         new_height = height\n",
    "#         new_width = int(height * target_aspect_ratio)\n",
    "#         left = (width - new_width) // 2\n",
    "#         right = left + new_width\n",
    "#         top = 0\n",
    "#         bottom = height\n",
    "#     else:\n",
    "#         new_width = width\n",
    "#         new_height = int(width / target_aspect_ratio)\n",
    "#         top = (height - new_height) // 2\n",
    "#         bottom = top + new_height\n",
    "#         left = 0\n",
    "#         right = width\n",
    "\n",
    "#     img = img[top:bottom, left:right]\n",
    "\n",
    "#     img = image.smart_resize(img, (224, 224))\n",
    "\n",
    "#     x = img / 255.0\n",
    "\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#     predictions = model.predict(x)\n",
    "    \n",
    "#     class_names = ['call_me', 'okay', 'paper','Rock','up']\n",
    "#     predicted_class_idx = np.argmax(predictions)\n",
    "#     predicted_class = class_names[predicted_class_idx]\n",
    "#     return predicted_class\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
