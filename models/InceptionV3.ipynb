{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To split Test and Train Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "original_dataset_dir = 'D:\\Btech_AI\\Projects\\Gesture-recognition\\Dataset\\images'\n",
    "base_dir = 'D:\\Btech_AI\\Projects\\Gesture-recognition\\Dataset'\n",
    "\n",
    "# Create base directory\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['call_me', 'rock_on', 'fingers_crossed', 'okay', 'paper', 'peace', 'rock', 'scissor', 'thumbs', 'up']\n",
    "\n",
    "# Create train and test directories\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Copy images to train and test directories\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(original_dataset_dir, class_name)\n",
    "    images = [os.path.join(class_dir, img) for img in os.listdir(class_dir)]\n",
    "    train_images, test_images = train_test_split(images, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Copy train images\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    for img in train_images:\n",
    "        shutil.copy(img, train_class_dir)\n",
    "    \n",
    "    # Copy test images\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    for img in test_images:\n",
    "        shutil.copy(img, test_class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4248 images belonging to 10 classes.\n",
      "Found 467 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Data loading and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.10  # Splitting the data into training and validation sets\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:\\\\Btech_AI\\\\Projects\\\\Gesture-recognition\\\\Dataset\\\\train',\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'D:\\\\Btech_AI\\\\Projects\\\\Gesture-recognition\\\\Dataset\\\\train',\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without K-fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "132/132 [==============================] - 57s 412ms/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: 0.1084 - val_accuracy: 0.9621\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 54s 411ms/step - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.2645 - val_accuracy: 0.9174\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 127s 966ms/step - loss: 0.0538 - accuracy: 0.9824 - val_loss: 0.1194 - val_accuracy: 0.9598\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 157s 1s/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.1677 - val_accuracy: 0.9487\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 118s 890ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.3094 - val_accuracy: 0.9263\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 59s 438ms/step - loss: 0.0362 - accuracy: 0.9865 - val_loss: 0.1850 - val_accuracy: 0.9487\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 60s 457ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.1255 - val_accuracy: 0.9509\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 107s 804ms/step - loss: 0.0697 - accuracy: 0.9796 - val_loss: 0.3903 - val_accuracy: 0.9107\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 91s 693ms/step - loss: 0.0464 - accuracy: 0.9870 - val_loss: 0.2582 - val_accuracy: 0.9286\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 55s 414ms/step - loss: 0.0301 - accuracy: 0.9905 - val_loss: 0.1384 - val_accuracy: 0.9643\n",
      "133/133 [==============================] - 48s 359ms/step - loss: 0.0151 - accuracy: 0.9955\n",
      "15/15 [==============================] - 6s 362ms/step - loss: 0.1274 - accuracy: 0.9657\n",
      "Training Loss: 0.015055340714752674\n",
      "Training Accuracy: 0.9955273270606995\n",
      "Validation Loss: 0.12744124233722687\n",
      "Validation Accuracy: 0.9657387733459473\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "# Evaluate the model on the entire training set\n",
    "train_loss, train_accuracy = model.evaluate(train_generator, verbose=1)\n",
    "\n",
    "# Evaluate the model on the entire validation set\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai Chiranthan H M\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('gesture_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1053 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D:\\\\Btech_AI\\\\Projects\\\\Gesture-recognition\\\\Dataset\\\\test',\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Set shuffle to False for the testing set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 13s 342ms/step - loss: 0.0707 - accuracy: 0.9782\n",
      "Test Accuracy: 0.978157639503479\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('gesture_recognition_model.h5')\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 96s 701ms/step - loss: 2.3010 - accuracy: 0.1105 - val_loss: 2.2969 - val_accuracy: 0.0982\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 92s 700ms/step - loss: 2.2860 - accuracy: 0.1347 - val_loss: 2.2673 - val_accuracy: 0.1830\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 94s 712ms/step - loss: 2.2443 - accuracy: 0.1788 - val_loss: 2.2134 - val_accuracy: 0.1853\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 91s 687ms/step - loss: 2.1825 - accuracy: 0.1895 - val_loss: 2.1624 - val_accuracy: 0.2455\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 89s 675ms/step - loss: 2.1253 - accuracy: 0.1976 - val_loss: 2.1108 - val_accuracy: 0.2411\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 92s 693ms/step - loss: 2.0820 - accuracy: 0.2132 - val_loss: 2.0801 - val_accuracy: 0.2679\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 91s 689ms/step - loss: 2.0569 - accuracy: 0.2125 - val_loss: 2.0616 - val_accuracy: 0.2879\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 92s 696ms/step - loss: 2.0375 - accuracy: 0.2071 - val_loss: 2.0539 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 93s 701ms/step - loss: 2.0207 - accuracy: 0.2166 - val_loss: 2.0140 - val_accuracy: 0.2567\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 93s 707ms/step - loss: 2.0058 - accuracy: 0.2168 - val_loss: 2.0374 - val_accuracy: 0.2634\n",
      "Fold 2/5\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 97s 709ms/step - loss: 2.2980 - accuracy: 0.1048 - val_loss: 2.2854 - val_accuracy: 0.1094\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 91s 685ms/step - loss: 2.2640 - accuracy: 0.1423 - val_loss: 2.2252 - val_accuracy: 0.1652\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 94s 713ms/step - loss: 2.1885 - accuracy: 0.1798 - val_loss: 2.1372 - val_accuracy: 0.1897\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 94s 708ms/step - loss: 2.1112 - accuracy: 0.1933 - val_loss: 2.0889 - val_accuracy: 0.2433\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 93s 700ms/step - loss: 2.0649 - accuracy: 0.2102 - val_loss: 2.0566 - val_accuracy: 0.2210\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 91s 693ms/step - loss: 2.0380 - accuracy: 0.2030 - val_loss: 2.0314 - val_accuracy: 0.2768\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 95s 721ms/step - loss: 2.0158 - accuracy: 0.2187 - val_loss: 2.0522 - val_accuracy: 0.2545\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 93s 702ms/step - loss: 2.0009 - accuracy: 0.2189 - val_loss: 1.9953 - val_accuracy: 0.2879\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 92s 698ms/step - loss: 1.9993 - accuracy: 0.2206 - val_loss: 2.0241 - val_accuracy: 0.2746\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 92s 695ms/step - loss: 1.9845 - accuracy: 0.2241 - val_loss: 1.9850 - val_accuracy: 0.2768\n",
      "Fold 3/5\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 98s 715ms/step - loss: 2.2999 - accuracy: 0.1041 - val_loss: 2.2922 - val_accuracy: 0.1116\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 91s 692ms/step - loss: 2.2793 - accuracy: 0.1312 - val_loss: 2.2534 - val_accuracy: 0.1562\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 95s 721ms/step - loss: 2.2249 - accuracy: 0.1743 - val_loss: 2.1805 - val_accuracy: 0.2054\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 94s 708ms/step - loss: 2.1494 - accuracy: 0.1905 - val_loss: 2.1133 - val_accuracy: 0.2098\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 97s 737ms/step - loss: 2.0942 - accuracy: 0.2104 - val_loss: 2.0662 - val_accuracy: 0.2366\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 106s 801ms/step - loss: 2.0572 - accuracy: 0.2211 - val_loss: 2.0388 - val_accuracy: 0.2656\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 107s 814ms/step - loss: 2.0323 - accuracy: 0.2275 - val_loss: 2.0137 - val_accuracy: 0.2723\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 131s 995ms/step - loss: 2.0125 - accuracy: 0.2374 - val_loss: 1.9946 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 164s 1s/step - loss: 1.9991 - accuracy: 0.2372 - val_loss: 2.0053 - val_accuracy: 0.2924\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 164s 1s/step - loss: 1.9867 - accuracy: 0.2374 - val_loss: 1.9977 - val_accuracy: 0.2701\n",
      "Fold 4/5\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 178s 1s/step - loss: 2.2992 - accuracy: 0.1025 - val_loss: 2.2916 - val_accuracy: 0.1429\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 164s 1s/step - loss: 2.2738 - accuracy: 0.1307 - val_loss: 2.2526 - val_accuracy: 0.1696\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 162s 1s/step - loss: 2.2153 - accuracy: 0.1812 - val_loss: 2.1713 - val_accuracy: 0.1741\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 2174s 17s/step - loss: 2.1497 - accuracy: 0.1871 - val_loss: 2.1272 - val_accuracy: 0.2299\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 52s 396ms/step - loss: 2.0969 - accuracy: 0.2035 - val_loss: 2.0676 - val_accuracy: 0.1987\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 53s 402ms/step - loss: 2.0660 - accuracy: 0.2123 - val_loss: 2.0530 - val_accuracy: 0.2076\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 53s 401ms/step - loss: 2.0408 - accuracy: 0.2151 - val_loss: 2.0417 - val_accuracy: 0.2634\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 52s 394ms/step - loss: 2.0248 - accuracy: 0.2284 - val_loss: 2.0261 - val_accuracy: 0.2321\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 52s 395ms/step - loss: 2.0163 - accuracy: 0.2251 - val_loss: 2.0078 - val_accuracy: 0.2656\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 56s 423ms/step - loss: 2.0056 - accuracy: 0.2355 - val_loss: 1.9949 - val_accuracy: 0.2679\n",
      "Fold 5/5\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 59s 415ms/step - loss: 2.2981 - accuracy: 0.1018 - val_loss: 2.2863 - val_accuracy: 0.1049\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 53s 404ms/step - loss: 2.2635 - accuracy: 0.1487 - val_loss: 2.2227 - val_accuracy: 0.1920\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 54s 405ms/step - loss: 2.1827 - accuracy: 0.1886 - val_loss: 2.1413 - val_accuracy: 0.2009\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 54s 407ms/step - loss: 2.1116 - accuracy: 0.2037 - val_loss: 2.0705 - val_accuracy: 0.2031\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 53s 403ms/step - loss: 2.0752 - accuracy: 0.2106 - val_loss: 2.0514 - val_accuracy: 0.2098\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 54s 406ms/step - loss: 2.0483 - accuracy: 0.2192 - val_loss: 2.0180 - val_accuracy: 0.2254\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 106s 806ms/step - loss: 2.0346 - accuracy: 0.2189 - val_loss: 2.0140 - val_accuracy: 0.2277\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 78s 585ms/step - loss: 2.0214 - accuracy: 0.2237 - val_loss: 2.0268 - val_accuracy: 0.2165\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 53s 404ms/step - loss: 2.0100 - accuracy: 0.2441 - val_loss: 1.9935 - val_accuracy: 0.2321\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 53s 403ms/step - loss: 2.0037 - accuracy: 0.2315 - val_loss: 1.9992 - val_accuracy: 0.3013\n",
      "Average Training Loss: 1.9909199237823487\n",
      "Average Training Accuracy: 0.23898304700851442\n",
      "Average Validation Loss: 2.006751275062561\n",
      "Average Validation Accuracy: 0.2817987084388733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 5  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Lists to store the evaluation results\n",
    "fold_train_losses = []\n",
    "fold_train_accuracies = []\n",
    "fold_val_losses = []\n",
    "fold_val_accuracies = []\n",
    "\n",
    "# Iterate over folds\n",
    "# Perform K-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(train_generator)):\n",
    "    print(f\"Fold {fold+1}/{k}\")\n",
    "    ''' \n",
    "   # Split data into training and validation sets\n",
    "    train_generator.reset()  # Reset generator to ensure consistent indexing\n",
    "    train_data = train_generator.flow_from_directory(\n",
    "        'D:\\\\Btech_AI\\\\Projects\\\\Gesture-recognition\\\\Dataset\\\\train',\n",
    "        target_size=(input_shape[0], input_shape[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=False,  # Shuffle should be False to maintain consistency with the fold indices\n",
    "        indices=train_index\n",
    "    )\n",
    "    \n",
    "    val_generator.reset()  # Reset generator to ensure consistent indexing\n",
    "    val_data = val_generator.flow_from_directory(\n",
    "        'D:\\\\Btech_AI\\\\Projects\\\\Gesture-recognition\\\\Dataset\\\\train',\n",
    "        target_size=(input_shape[0], input_shape[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False,  # Shuffle should be False to maintain consistency with the fold indices\n",
    "        indices=val_index\n",
    "    )\n",
    "    '''\n",
    "    # Clone the model\n",
    "    model_clone = tf.keras.models.clone_model(model)\n",
    "    model_clone.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    history = model_clone.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on training set\n",
    "    train_loss, train_accuracy = model_clone.evaluate(train_generator, verbose=0)\n",
    "    fold_train_losses.append(train_loss)\n",
    "    fold_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Evaluate the model on validation set\n",
    "    val_loss, val_accuracy = model_clone.evaluate(validation_generator, verbose=0)\n",
    "    fold_val_losses.append(val_loss)\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_train_loss = np.mean(fold_train_losses)\n",
    "avg_train_accuracy = np.mean(fold_train_accuracies)\n",
    "avg_val_loss = np.mean(fold_val_losses)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "\n",
    "print(f\"Average Training Loss: {avg_train_loss}\")\n",
    "print(f\"Average Training Accuracy: {avg_train_accuracy}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 9s 284ms/step - loss: 0.0264 - accuracy: 0.9905\n",
      "Test Accuracy: before K-fold cross validation 0.9905033111572266\n",
      "33/33 [==============================] - 10s 290ms/step - loss: 1.9646 - accuracy: 0.2593\n",
      "Test Accuracy: After K-fold cross validation 0.25925925374031067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test Accuracy: before K-fold cross validation\", test_accuracy)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_accuracy = model_clone.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(\"Test Accuracy: After K-fold cross validation\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
